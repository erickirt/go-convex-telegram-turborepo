# Centralized Environment Configuration for Telegram Bot + Convex Backend


# =============================================================================
# TELEGRAM BOT CONFIGURATION
# =============================================================================
# Get your bot token from @BotFather on Telegram
TELEGRAM_TOKEN=7699094377:AAG4wX5TnPTMDMb_3YQ_SJFestxJCibkKXM

# Your bot's username (without @, but including _bot suffix)
# Example: rust_telegram_bot_example_bot
# This is used to construct the bot URL: t.me/{TELEGRAM_BOT_USERNAME}
TELEGRAM_BOT_USERNAME=devKessBot

# =============================================================================
# CONVEX BACKEND CONFIGURATION
# =============================================================================
# Backend service ports
NEXT_PUBLIC_CONVEX_PORT=3210
NEXT_PUBLIC_CONVEX_SITE_PROXY_PORT=3211
CONVEX_ADMIN_KEY=0000000000000000000000000000000000000000000000000000000000000000

# Bot should connect to the site proxy port (3211) where API endpoints are available
CONVEX_URL=http://convex-backend:3211
CONVEX_DASHBOARD_PORT=6791

# Instance configuration
# IMPORTANT: Change this secret for production!
CONVEX_INSTANCE_NAME=convex-telegram-bot
CONVEX_INSTANCE_SECRET=0000000000000000000000000000000000000000000000000000000000000000

# Convex URLs for self-hosted deployment
CONVEX_CLOUD_ORIGIN=http://127.0.0.1:3211
CONVEX_SITE_ORIGIN=http://127.0.0.1:3211
NEXT_PUBLIC_DEPLOYMENT_URL=http://127.0.0.1:3211

# Web Dashboard Configuration
WEB_DASHBOARD_PORT=3000
# For browser connections (client-side) - Use actual Convex backend port for React client
NEXT_PUBLIC_CONVEX_URL=http://localhost:3210
NEXT_PUBLIC_CONVEX_WS_URL=ws://localhost:3210
# For server-side connections within Docker network
CONVEX_HTTP_URL=http://convex-backend:3211

# LLM Service Ports
LIGHTWEIGHT_LLM_PORT=8082
VECTOR_CONVERT_PORT=7999

# LLM Service URLs for browser access
NEXT_PUBLIC_VECTOR_CONVERT_LLM_URL=http://localhost:7999
NEXT_PUBLIC_LIGHTWEIGHT_LLM_URL=http://localhost:8082

# Model Configuration (Next.js Public Environment Variables)
# These are exposed to the client-side and displayed in the UI
NEXT_PUBLIC_VECTOR_CONVERT_MODEL="all-MiniLM-L6-v2"
NEXT_PUBLIC_VECTOR_CONVERT_MODEL_HUGGINGFACE_URL="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
NEXT_PUBLIC_LLM_MODEL="Meta Llama 3.2"
NEXT_PUBLIC_LLM_MODEL_HUGGINGFACE_URL="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"

# Development settings
CONVEX_RELEASE_VERSION_DEV=
DO_NOT_REQUIRE_SSL=true
DISABLE_BEACON=true
REDACT_LOGS_TO_CLIENT=false

# Logging
RUST_LOG=info
RUST_BACKTRACE=

# Optional: External database configuration (leave empty to use built-in storage)
DATABASE_URL=
POSTGRES_URL=
MYSQL_URL=

# Optional: AWS S3 configuration for file storage
AWS_REGION=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=
S3_STORAGE_EXPORTS_BUCKET=
S3_STORAGE_SNAPSHOT_IMPORTS_BUCKET=
S3_STORAGE_MODULES_BUCKET=
S3_STORAGE_FILES_BUCKET=
S3_STORAGE_SEARCH_BUCKET=
S3_ENDPOINT_URL=
NEXT_PUBLIC_RAM_AVAILABLE=8G
NEXT_PUBLIC_CONVEX_BACKEND_RAM=4.0G
NEXT_PUBLIC_CONVEX_DASHBOARD_RAM=491M
NEXT_PUBLIC_TELEGRAM_BOT_RAM=327M
NEXT_PUBLIC_VECTOR_CONVERT_LLM_RAM=2.3G
NEXT_PUBLIC_LIGHTWEIGHT_LLM_RAM=8.0G
NEXT_PUBLIC_WEB_DASHBOARD_RAM=819M
NEXT_PUBLIC_TOTAL_RAM_ALLOCATED=16G
