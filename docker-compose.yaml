# Z-production deployment/docker-compose.yaml
name: telegram-bot

services:
  # Convex Backend Service
  convex-backend:
    image: ghcr.io/get-convex/convex-backend:c1a7ac393888d743e704de56cf569a154b4526d4
    stop_grace_period: 10s
    stop_signal: SIGINT
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    ports:
      - "${CONVEX_PORT:-3210}:3210"
      - "${CONVEX_SITE_PROXY_PORT:-3211}:3211"
    volumes:
      - convex_data:/convex/data
      - ./apps/docker-convex/admin-key:/convex/admin-key
    environment:
      - INSTANCE_NAME=${CONVEX_INSTANCE_NAME:-convex-telegram-bot}
      - INSTANCE_SECRET=${CONVEX_INSTANCE_SECRET:-0000000000000000000000000000000000000000000000000000000000000000}
      - CONVEX_RELEASE_VERSION_DEV=${CONVEX_RELEASE_VERSION_DEV:-}
      - ACTIONS_USER_TIMEOUT_SECS=${ACTIONS_USER_TIMEOUT_SECS:-}
      - CONVEX_CLOUD_ORIGIN=${CONVEX_CLOUD_ORIGIN:-http://127.0.0.1:3210}
      - CONVEX_SITE_ORIGIN=${CONVEX_SITE_ORIGIN:-http://127.0.0.1:3211}
      - DATABASE_URL=${DATABASE_URL:-}
      - DISABLE_BEACON=${DISABLE_BEACON:-true}
      - REDACT_LOGS_TO_CLIENT=${REDACT_LOGS_TO_CLIENT:-false}
      - DO_NOT_REQUIRE_SSL=${DO_NOT_REQUIRE_SSL:-true}
      - POSTGRES_URL=${POSTGRES_URL:-}
      - MYSQL_URL=${MYSQL_URL:-}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-}
      - AWS_REGION=${AWS_REGION:-}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN:-}
      - S3_STORAGE_EXPORTS_BUCKET=${S3_STORAGE_EXPORTS_BUCKET:-}
      - S3_STORAGE_SNAPSHOT_IMPORTS_BUCKET=${S3_STORAGE_SNAPSHOT_IMPORTS_BUCKET:-}
      - S3_STORAGE_MODULES_BUCKET=${S3_STORAGE_MODULES_BUCKET:-}
      - S3_STORAGE_FILES_BUCKET=${S3_STORAGE_FILES_BUCKET:-}
      - S3_STORAGE_SEARCH_BUCKET=${S3_STORAGE_SEARCH_BUCKET:-}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL:-}
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
    healthcheck:
      test: curl -f http://localhost:3210/version
      interval: 5s
      start_period: 10s
    networks:
      - telegram-bot-network

  # Convex Dashboard Service
  convex-dashboard:
    image: ghcr.io/get-convex/convex-dashboard:c1a7ac393888d743e704de56cf569a154b4526d4
    stop_grace_period: 10s
    stop_signal: SIGINT
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
    ports:
      - "${CONVEX_DASHBOARD_PORT:-6791}:6791"
    environment:
      - NEXT_PUBLIC_DEPLOYMENT_URL=${NEXT_PUBLIC_DEPLOYMENT_URL:-http://127.0.0.1:3210}
    depends_on:
      convex-backend:
        condition: service_healthy
      vector-convert-llm:
        condition: service_healthy
    networks:
      - telegram-bot-network

  # Telegram bot written in Go
  telegram-bot:
      build:
        context: ./apps/golang-telegram-bot
        dockerfile: Dockerfile
      deploy:
        resources:
          limits:
            memory: 128M
          reservations:
            memory: 64M
      environment:
        - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
        - CONVEX_URL=http://convex-backend:3211
        - CONVEX_INSTANCE_SECRET=${CONVEX_INSTANCE_SECRET:-0000000000000000000000000000000000000000000000000000000000000000}
        - VECTOR_CONVERT_LLM_URL=http://vector-convert-llm:8081
      depends_on:
        convex-backend:
          condition: service_healthy
        vector-convert-llm:
          condition: service_healthy
      restart: unless-stopped
      networks:
        - telegram-bot-network



  # Vector Convert LLM Service (Optimized & Stable)
  vector-convert-llm:
    build:
      context: ./apps/vector-convert-llm
      dockerfile: Dockerfile
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    ports:
      - "8081:8081"
    environment:
      - PORT=8081
      - CONVEX_URL=http://convex-backend:3211
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - TRANSFORMERS_CACHE=/app/cache/transformers
      - HF_HOME=/app/cache/huggingface
      - TOKENIZERS_PARALLELISM=false
      - OMP_NUM_THREADS=1
      - MKL_NUM_THREADS=1
      - OPENBLAS_NUM_THREADS=1
      - NUMEXPR_NUM_THREADS=1
      - VECLIB_MAXIMUM_THREADS=1
    depends_on:
      convex-backend:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - telegram-bot-network
    healthcheck:
      test: curl -f http://localhost:8081/health || exit 1
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 5

  # Lightweight LLM service for document chat
  lightweight-llm:
      build:
        context: ./apps/lightweight-llm
        dockerfile: Dockerfile
      deploy:
        resources:
          limits:
            memory: 6G
          reservations:
            memory: 3G
      ports:
        - "8082:8082"
      environment:
        - PORT=8082
        - PYTHONUNBUFFERED=1
        - PYTHONDONTWRITEBYTECODE=1
        - MODEL_PATH=./Phi-3-mini-4k-instruct-q4.gguf
        - N_CTX=4096
        - N_THREADS=8
        - N_GPU_LAYERS=0
        - OMP_NUM_THREADS=8
        - MKL_NUM_THREADS=8
        - OPENBLAS_NUM_THREADS=8
        - NUMEXPR_NUM_THREADS=8
        - VECLIB_MAXIMUM_THREADS=8
      depends_on:
        convex-backend:
          condition: service_healthy
      restart: on-failure:3
      networks:
        - telegram-bot-network
      healthcheck:
        test: curl -f http://localhost:8082/health || exit 1
        interval: 30s
        timeout: 15s
        start_period: 180s
        retries: 5

   # Next.js Web Dashboard Service
  web-dashboard:
    build:
      context: .
      dockerfile: ./apps/web/Dockerfile
      args:
        - NEXT_PUBLIC_CONVEX_URL=${NEXT_PUBLIC_CONVEX_URL:-http://localhost:3210}
        - NEXT_PUBLIC_TELEGRAM_BOT_USERNAME=${TELEGRAM_BOT_USERNAME}
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    ports:
      - "${WEB_DASHBOARD_PORT:-3000}:3000"
    environment:
      - NEXT_PUBLIC_CONVEX_URL=${NEXT_PUBLIC_CONVEX_URL:-http://localhost:3210}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_TOKEN}
      - NEXT_PUBLIC_TELEGRAM_BOT_USERNAME=${TELEGRAM_BOT_USERNAME}
      - CONVEX_URL=http://convex-backend:3211
      - CONVEX_HTTP_URL=http://convex-backend:3211
      - VECTOR_CONVERT_LLM_INTERNAL_URL=http://vector-convert-llm:8081
      - VECTOR_CONVERT_LLM_URL=http://vector-convert-llm:8081
      - NEXT_PUBLIC_VECTOR_CONVERT_LLM_URL=${NEXT_PUBLIC_VECTOR_CONVERT_LLM_URL:-http://localhost:8081}
      - LIGHTWEIGHT_LLM_INTERNAL_URL=http://lightweight-llm:8082
      - LIGHTWEIGHT_LLM_URL=http://lightweight-llm:8082
      - NEXT_PUBLIC_LIGHTWEIGHT_LLM_URL=${NEXT_PUBLIC_LIGHTWEIGHT_LLM_URL:-http://localhost:8082}
      - NODE_ENV=production
      - NEXT_PUBLIC_CONVEX_DASHBOARD_PORT=${CONVEX_DASHBOARD_PORT:-6791}
      - NEXT_PUBLIC_CONVEX_PORT=${CONVEX_PORT:-3210}
      - NEXT_PUBLIC_VECTOR_CONVERT_MODEL=${NEXT_PUBLIC_VECTOR_CONVERT_MODEL:-all-MiniLM-L6-v2}
      - NEXT_PUBLIC_VECTOR_CONVERT_MODEL_HUGGINGFACE_URL=${NEXT_PUBLIC_VECTOR_CONVERT_MODEL_HUGGINGFACE_URL:-https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2}
      - NEXT_PUBLIC_LLM_MODEL=${NEXT_PUBLIC_LLM_MODEL:-Meta Llama 3.2}
      - NEXT_PUBLIC_LLM_MODEL_HUGGINGFACE_URL=${NEXT_PUBLIC_LLM_MODEL_HUGGINGFACE_URL:-https://huggingface.co/meta-llama/Llama-2-7b-chat-hf}
    depends_on:
      convex-backend:
        condition: service_healthy
      lightweight-llm:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - telegram-bot-network

volumes:
  convex_data:

networks:
  telegram-bot-network:
    driver: bridge

